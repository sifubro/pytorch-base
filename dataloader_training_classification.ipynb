{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4515c2-8ef8-4aa8-89af-83ebdf9bab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b31ccc5-cbea-4a32-a4a3-ed1a892dec22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x243556f76d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the seed\n",
    "SEED = 1234\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "#tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e81e1a-5378-4464-bbb6-54c1790cc586",
   "metadata": {},
   "source": [
    "### csv with filenames and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1912d570-23d4-4221-b0cb-192f15a4d742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = glob.glob(\"D://DATASETS/DogsVsCats/train-val-test/*.jpg\")\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea7e89e-2212-4339-a102-a2132e236004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\cat.0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\cat.1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\cat.10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label\n",
       "0   D://DATASETS/DogsVsCats/train-val-test\\cat.0.jpg      0\n",
       "1   D://DATASETS/DogsVsCats/train-val-test\\cat.1.jpg      0\n",
       "2  D://DATASETS/DogsVsCats/train-val-test\\cat.10.jpg      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [1 if \"dog\" in fname else 0 for fname in images]\n",
    "full_df = pd.DataFrame()\n",
    "full_df[\"filename\"] = images\n",
    "full_df[\"label\"] = labels\n",
    "full_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7bade-1933-4f32-8602-3370545c95a1",
   "metadata": {},
   "source": [
    "### Shuffle dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a4166a-ebd4-493b-8ac7-06db0286d11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5262</td>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\cat.348...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22764</td>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\dog.798...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2633</td>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\cat.123...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22512</td>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\dog.776...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19404</td>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\dog.496...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           filename  label\n",
       "0   5262  D://DATASETS/DogsVsCats/train-val-test\\cat.348...      0\n",
       "1  22764  D://DATASETS/DogsVsCats/train-val-test\\dog.798...      1\n",
       "2   2633  D://DATASETS/DogsVsCats/train-val-test\\cat.123...      0\n",
       "3  22512  D://DATASETS/DogsVsCats/train-val-test\\dog.776...      1\n",
       "4  19404  D://DATASETS/DogsVsCats/train-val-test\\dog.496...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = full_df.sample(frac=1).reset_index()\n",
    "full_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a59721-7309-4112-ae2d-1025d1fcbafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09a0293d-519c-43b6-8e24-62a607a47c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dogs_df = full_df[full_df.label==1].sample(frac=1).reset_index(drop=True)\n",
    "cats_df = full_df[full_df.label==0].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "dogs = {\"train\":None, \"test\": None, \"valid\":None}\n",
    "cats = {\"train\":None, \"test\": None, \"valid\":None}\n",
    "\n",
    "dogs[\"train\"], dogs[\"test\"], dogs[\"valid\"] = np.split(dogs_df, [int(0.8*len(dogs_df)), int(0.9*len(dogs_df))])\n",
    "cats[\"train\"], cats[\"test\"], cats[\"valid\"] = np.split(cats_df, [int(0.8*len(cats_df)), int(0.9*len(cats_df))])\n",
    "\n",
    "train_df = pd.concat([dogs[\"train\"], cats[\"train\"]]).sample(frac=1).reset_index(drop=True)\n",
    "test_df = pd.concat([dogs[\"test\"], cats[\"test\"]]).sample(frac=1).reset_index(drop=True)\n",
    "valid_df = pd.concat([dogs[\"valid\"], cats[\"valid\"]]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3adc6af5-0d2f-477c-8e48-9ac06c6ae15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2500, 2500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df), len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad8d69e8-79d7-4e4a-aee9-39ff1ca45924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1550</td>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\cat.113...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19077</td>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\dog.466...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5690</td>\n",
       "      <td>D://DATASETS/DogsVsCats/train-val-test\\cat.387...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           filename  label\n",
       "0   1550  D://DATASETS/DogsVsCats/train-val-test\\cat.113...      0\n",
       "1  19077  D://DATASETS/DogsVsCats/train-val-test\\dog.466...      1\n",
       "2   5690  D://DATASETS/DogsVsCats/train-val-test\\cat.387...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308029a0-468d-4602-a07d-82172031c0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc93def-fd91-4ec1-b6c6-9bc5bb80c40b",
   "metadata": {},
   "source": [
    "### `Dataset` stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "\n",
    "#### https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler\n",
    "#### https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
    "\n",
    "### TODO: Sampler\n",
    "\n",
    "#### https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f025fa26-46b7-47ba-b478-9a7a4e7f001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    '''\n",
    "    https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    '''\n",
    "    def __init__(self, train_df, transform=None, target_transform=None):\n",
    "        self.train_df = train_df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = train_df.filename[idx]\n",
    "        # read JPEG or PNG image from filepath  --> output (Tensor[image_channels, image_height, image_width])\n",
    "        image =  read_image(img_path)\n",
    "        label =  train_df.label[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            # These are transformation single level\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return {'image': image, 'label': label}  #image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb0846-3835-43be-a793-a15bdfa1e5fa",
   "metadata": {},
   "source": [
    "### https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5ae26bb-9dc8-4b5a-972a-299248c6d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        landmarks = landmarks * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'landmarks': landmarks}\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h + 1)\n",
    "        left = np.random.randint(0, w - new_w + 1)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        landmarks = landmarks - [left, top]\n",
    "\n",
    "        return {'image': image, 'landmarks': landmarks}\n",
    "        \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'label': torch.from_numpy(label)}\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = 2*(image/255.0) - 1 # between -1 and +1\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9fb143c-964b-4496-8d4e-f24e3d6ee5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transforms_train = transforms.Compose([Normalize(),\n",
    "                                transforms.Resize(256),\n",
    "                               transforms.RandomCrop(224)\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b9dcbc3-62e1-45bb-8db3-ded40a8389b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomImageDataset at 0x24361a88eb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = CustomImageDataset(train_df,transform=transforms_train)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27f176e0-c34c-4348-89cd-c36515ceb4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 2500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df), len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6d5bc0f-e180-474b-be12-f11e27a5a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transforms_test_valid = transforms.Compose([Normalize(),\n",
    "                                transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224)\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66f58cf4-21ec-4c96-aae9-866ca504eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CustomImageDataset(test_df, transform=transforms_test_valid)\n",
    "valid_ds = CustomImageDataset(valid_df, transform=transforms_test_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63f5c117-9cec-4019-a95f-e53f1dbebe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2500, 2500)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(test_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8a9f52a-cd81-43f9-9ec4-c4741797895c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': tensor([[[ 0.6087,  0.6985,  0.7399,  ..., -0.4219, -0.4297, -0.4291],\n",
      "         [ 0.6239,  0.7386,  0.8176,  ..., -0.4195, -0.4311, -0.4340],\n",
      "         [ 0.6363,  0.7401,  0.8583,  ..., -0.4195, -0.4311, -0.4353],\n",
      "         ...,\n",
      "         [ 0.7515,  0.7453,  0.7418,  ..., -0.2777, -0.2747, -0.2706],\n",
      "         [ 0.7417,  0.7361,  0.7313,  ..., -0.2735, -0.2699, -0.2674],\n",
      "         [ 0.7519,  0.7473,  0.7442,  ..., -0.2582, -0.2572, -0.2534]],\n",
      "\n",
      "        [[ 0.7476,  0.8166,  0.8444,  ..., -0.4063, -0.4140, -0.4122],\n",
      "         [ 0.7617,  0.8518,  0.9103,  ..., -0.4038, -0.4154, -0.4170],\n",
      "         [ 0.7644,  0.8470,  0.9457,  ..., -0.4038, -0.4154, -0.4183],\n",
      "         ...,\n",
      "         [ 0.7751,  0.7689,  0.7653,  ..., -0.3404, -0.3375, -0.3333],\n",
      "         [ 0.7652,  0.7596,  0.7548,  ..., -0.3362, -0.3326, -0.3301],\n",
      "         [ 0.7755,  0.7709,  0.7677,  ..., -0.3210, -0.3199, -0.3161]],\n",
      "\n",
      "        [[ 0.6973,  0.7622,  0.7794,  ..., -0.4298, -0.4449, -0.4539],\n",
      "         [ 0.7120,  0.7974,  0.8492,  ..., -0.4274, -0.4463, -0.4588],\n",
      "         [ 0.7211,  0.7928,  0.8853,  ..., -0.4274, -0.4463, -0.4601],\n",
      "         ...,\n",
      "         [ 0.8143,  0.8081,  0.8155,  ..., -0.4894, -0.4865, -0.4824],\n",
      "         [ 0.8045,  0.7989,  0.8050,  ..., -0.4853, -0.4817, -0.4791],\n",
      "         [ 0.8147,  0.8101,  0.8180,  ..., -0.4700, -0.4690, -0.4651]]]), 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "for item in train_ds:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5fffa53-6710-4e38-842d-1d2f4172f8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps or torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c32321c3-7bde-4c26-83db-3aa8568b59f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3222977-502e-4d46-9467-be19f67dd581",
   "metadata": {},
   "source": [
    "## Dataloader - Batching shuffling etc\n",
    "#### `https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader`\n",
    "\n",
    "\n",
    "### TODO: optimize dataloader\n",
    "- TFRecords\n",
    "- interleave\n",
    "- .map() operations\n",
    "- batch level `transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f40f20a7-569b-4606-9397-22f36965e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a07730f-c642-4fe1-a870-9c7a88e74e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: How can I increase the batch size?\n",
    "valid_dataloader =  DataLoader(valid_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_dataloader =  DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057556e2-4129-4718-9954-9c28e4f4aeed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "208a2ed7-c8af-430e-87ba-bbdb6f3f0c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 3, 224, 224]), torch.Size([256]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_iterator = iter(train_dataloader)\n",
    "train_sample = next(train_iterator)\n",
    "train_features, train_labels = train_sample[\"image\"], train_sample[\"label\"]\n",
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cba03550-9e0e-43d8-88b3-59ea11b216f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#next(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e398224-c68b-44a8-877a-8ee823f48f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a4fd7f2-46d1-4d68-bc10-ca6f7f0fb371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbc0184c-abeb-4d5b-b1bc-56a6803851cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 254, 254]             448\n",
      "         MaxPool2d-2         [-1, 16, 127, 127]               0\n",
      "            Conv2d-3         [-1, 32, 125, 125]           4,640\n",
      "         MaxPool2d-4           [-1, 32, 62, 62]               0\n",
      "            Conv2d-5           [-1, 64, 60, 60]          18,496\n",
      "         MaxPool2d-6           [-1, 64, 30, 30]               0\n",
      "            Conv2d-7          [-1, 128, 28, 28]          73,856\n",
      "         MaxPool2d-8          [-1, 128, 14, 14]               0\n",
      " AdaptiveAvgPool2d-9            [-1, 128, 1, 1]               0\n",
      "           Linear-10                   [-1, 32]           4,128\n",
      "           Linear-11                    [-1, 1]              33\n",
      "================================================================\n",
      "Total params: 101,601\n",
      "Trainable params: 101,601\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 17.75\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 18.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = SimpleNet().to(device)\n",
    "#model = get_transformer()\n",
    "\n",
    "summary(model, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99198206-4005-4c16-8fc1-c46af14e9a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_features.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17950a7f-700f-4530-b729-2944259bc189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "544df5be-93ff-4a25-a0c5-dd6c206e4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# 1.15.0 or above\n",
    "# pip install numpy==1.23.5\n",
    "# pip install tensorboard==1.15.0\n",
    "# pip install tensorflow==2.7.0\n",
    "\n",
    "writer = SummaryWriter(\"tboard/cats_dogs_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4de6c700-f2f1-4fd0-b638-cae6838ed9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e74ed0a6-0970-4482-aba2-b3b89c603926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35d6e36a-533a-4244-8d77-2905c8b24117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-09\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=10**-4, eps=1e-9)\n",
    "\n",
    "optimizer_to(optimizer,device)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e71196a-438f-4a70-b12f-1d352a25510f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "loss_fn = nn.BCELoss().to(device)\n",
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8d27fbc-837b-474e-8ac3-4eb76b164e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningMeanMetric:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.sum = 0.0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.sum += value * n\n",
    "        self.count += n\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.sum = 0.0\n",
    "        self.count = 0\n",
    "\n",
    "    def value(self):\n",
    "        return self.sum / self.count if self.count > 0 else float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fafae94-4f25-4cc0-9212-01ba6197b8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac0967e2-beea-4837-836c-22ec7078984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SummaryMetric:\n",
    "\n",
    "#     def __init__(self, log_dir, name):\n",
    "#         self._summary_writer = tf.summary.create_file_writer(f\"{log_dir}/{name}\")\n",
    "\n",
    "#     def __call__(self, metrics, epoch, models_dict = None):\n",
    "#         with self._summary_writer.as_default():\n",
    "#             for metric_name, metric_value in metrics.items():\n",
    "#                 if \"image\" in metric_name:\n",
    "#                     if not \"images\" in metric_name:\n",
    "#                         metric_value = [metric_value]\n",
    "#                     tf.summary.image(metric_name, metric_value, max_outputs=16, step=epoch)\n",
    "#                 elif \"histogram\" in metric_name:\n",
    "#                     tf.summary.histogram(metric_name, metric_value, step=epoch)\n",
    "#                 elif \"grad\" in metric_name:\n",
    "#                     tf.summary.histogram(metric_name, metric_value, step=epoch)\n",
    "#                 else: #assume scalar\n",
    "#                     tf.summary.scalar(metric_name, metric_value, step=epoch)\n",
    "\n",
    "#         if models_dict is not None:\n",
    "#             for mname, model in models_dict.items():\n",
    "#                 for mlayer in model.layers():\n",
    "#                     try:\n",
    "#                         tf.summary.histogram(f\"{mname}-{mlayer.name}\", mlayer.weights[0], step= epoch)\n",
    "#                     except (ValueError, IndexError):\n",
    "#                         pass\n",
    "#         self._summary_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62fec43-0190-4598-893e-2d19dbe9788e",
   "metadata": {},
   "source": [
    "## https://pytorch.org/docs/stable/tensorboard.html\n",
    "### https://github.com/sifubro/pytorch-transformer/blob/main/train.py#L8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3696c5ef-a708-44d1-9877-f288b8315ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable CUDA error checking\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e2c947f-4514-4e0d-b17a-81742cd19177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 00: 100%|█████████████████████████████████████████████████████████████| 79/79 [01:10<00:00,  1.12it/s]\n",
      "Processing Epoch 01: 100%|█████████████████████████████████████████████████████████████| 79/79 [01:07<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "initial_epoch = 0\n",
    "last_epoch = 2\n",
    "global_step = 0\n",
    "\n",
    "save_dir = \"C://Users/SiFuBrO/Desktop/SCRIPTS!!!!!/GitHub/pytorch-base/checkpoints/cats_dogs_classifier_v1/\"\n",
    "metric_aggregators = {}\n",
    "metric_aggregators[\"train_loss_weighted\"] = RunningMeanMetric(name = \"train_loss_weighted\")\n",
    "\n",
    "for epoch in range(initial_epoch, last_epoch):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
    "    train_loss_epoch = []\n",
    "\n",
    "    # reset metric aggregators (i.e. running means)\n",
    "    for mname in  metric_aggregators.keys():\n",
    "        metric_aggregators[mname].reset_states()\n",
    "\n",
    "    for i, batch in enumerate(batch_iterator):\n",
    "\n",
    "        train_features = batch[\"image\"].to(device)\n",
    "        train_labels = batch[\"label\"].to(device)\n",
    "\n",
    "        # model output\n",
    "        output = model(train_features) # (B, 1)\n",
    "        output = torch.squeeze(output) # (B,)\n",
    "        # convert output from (B,1) -> (B,) and val_label cast from Long to float\n",
    "        if torch.isnan(output).any() or torch.isinf(output).any():\n",
    "            print(\"Ouput Tensor contains NaN or infinite values\")\n",
    "            global_step += 1\n",
    "            continue\n",
    "\n",
    "        train_loss = loss_fn(output, train_labels.type(torch.float))\n",
    "        # try:    \n",
    "        #     train_loss = loss_fn(output, train_labels.type(torch.float))\n",
    "        # except Exception as e:\n",
    "        #     print(f\"ERROR epoch {epoch} - iteration: {i}\")\n",
    "        #     print(e)\n",
    "        #     continue\n",
    "        train_loss_float = train_loss.item()\n",
    "        \n",
    "        # Log the loss\n",
    "        writer.add_scalar('train_loss_step', train_loss_float, global_step)\n",
    "        writer.flush()\n",
    "\n",
    "        metric_aggregators[\"train_loss_weighted\"].update(train_loss_float)\n",
    "        writer.add_scalar('train_loss_weighted', metric_aggregators[\"train_loss_weighted\"].value() , global_step)\n",
    "        writer.flush()\n",
    "        \n",
    "        # epoch loss\n",
    "        train_loss_epoch+= [train_loss_float] #.item()\n",
    "\n",
    "        # Backpropagate the loss\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        # set_to_none=True also sets the .grad attribute of each parameter to None. This can be helpful for memory efficiency and to avoid unintentional errors if gradients are accessed after they've been zeroed out.\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        global_step += 1\n",
    "        \n",
    "    writer.add_scalar('train_loss_epoch', np.mean(train_loss_epoch), global_step)\n",
    "    writer.flush()\n",
    "    \n",
    "    # Run validation at the end of every epoch\n",
    "    model.eval()\n",
    "    total_val_loss = []\n",
    "    val_outputs = []\n",
    "    y_true_labels = []\n",
    "    valid_iterator = iter(valid_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_iterator):\n",
    "            val_features =  batch[\"image\"].to(device)\n",
    "            # TODO: log some images in tensorboard\n",
    "            \n",
    "            val_labels =  batch[\"label\"].to(device)\n",
    "            val_output = model(val_features)[0] # from (1,1) [[0.67442]]  to-> (1) i.e., val_output = [0.67442] for examples\n",
    "            #val_labels is (1,) size i.e, [0] or [1]   \n",
    "\n",
    "            # validation loss\n",
    "            val_loss = loss_fn(val_output, val_labels.type(torch.float)).item()\n",
    "            total_val_loss += [val_loss]\n",
    "            \n",
    "            val_outputs += [val_output.item()]  # val_output = [0.67442] for examples \n",
    "            y_true_labels += [val_labels.item()]\n",
    "        \n",
    "        # Log the validation loss\n",
    "        writer.add_scalar('valid_loss', np.mean(total_val_loss), global_step)\n",
    "        writer.flush()\n",
    "\n",
    "        # TODO report validation accuracy\n",
    "\n",
    "        # Create ROC plots\n",
    "        fpr, tpr, thresholds = roc_curve(np.array(y_true_labels), np.array(val_outputs), pos_label=1)\n",
    "        f, (ax1, ax2) = plt.subplots(2,1, figsize=(8,12))\n",
    "        ax1.plot(fpr, tpr)\n",
    "        ax1.set_xlabel(\"FPR\")\n",
    "        ax1.set_ylabel(\"TPR\")\n",
    "        ax1.set_xscale('log', base=10)\n",
    "        ax1.set_ylim(0.0, 1.01)\n",
    "        ax1.set_title(\"ROC on validation set\")\n",
    "\n",
    "        ax2.plot(fpr, thresholds)\n",
    "        ax2.set_xlabel(\"FPR\")\n",
    "        ax2.set_ylabel(\"Thresholds\")\n",
    "        ax2.set_ylim(0.0, 1.01)\n",
    "\n",
    "        plt.axvline(x=0.005, color='black', ls=\":\", label=\"FPR=0.5%\")\n",
    "        plt.axvline(x=0.01, color='black', ls=\"--\", label=\"FPR=1%\")\n",
    "        writer.add_figure('ROC plot', plt.gcf(), global_step)\n",
    "        writer.flush()\n",
    "\n",
    "    \n",
    "    # Save the model at the end of every epoch\n",
    "    model_filename = f\"{save_dir}/{epoch}.pt\"\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'global_step': global_step\n",
    "        }, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9bf8869-fbb7-4fc2-83fb-05d96081b9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b49fb-6f84-431d-b420-57c750c9b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tensorboard\n",
    "tensorboard --logdir=C:\\Users\\SiFuBrO\\Desktop\\SCRIPTS!!!!!\\GitHub\\pytorch-base\\tboard\\cats_dogs_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfecf98-6b48-4303-b97d-f30d1d9e716a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b703733-c875-45a3-afc7-8a4ab2377ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14bf7547-77df-41d8-b3f6-82a126eff173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:16<00:00, 152.87it/s]\n"
     ]
    }
   ],
   "source": [
    "total_test_loss = []\n",
    "test_outputs = []\n",
    "test_true_labels = []\n",
    "test_iterator = iter(test_dataloader)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_iterator):\n",
    "        test_features =  batch[\"image\"].to(device)\n",
    "        # TODO: log some images in tensorboard\n",
    "        \n",
    "        test_labels =  batch[\"label\"].to(device)\n",
    "        test_output = model(test_features)[0] # from (1,1) [[0.67442]]  to-> (1) i.e., val_output = [0.67442] for examples\n",
    "        #val_labels is (1,) size i.e, [0] or [1]   \n",
    "\n",
    "        # validation loss\n",
    "        test_loss = loss_fn(test_output, test_labels.type(torch.float)).item()\n",
    "        total_test_loss += [test_loss]\n",
    "        \n",
    "        test_outputs += [test_output.item()]  # val_output = [0.67442] for examples \n",
    "        test_true_labels += [test_labels.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "074d7988-dd20-4ee3-8659-ee36a1158c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a382014-1ce4-408b-8a54-48f12f57fa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45040708780288696,\n",
       " 0.6275924444198608,\n",
       " 0.5663313269615173,\n",
       " 0.4341145157814026,\n",
       " 0.5830626487731934,\n",
       " 0.4998098909854889,\n",
       " 0.4678643047809601,\n",
       " 0.6071937084197998,\n",
       " 0.6597334146499634,\n",
       " 0.4435884654521942,\n",
       " 0.5784118175506592,\n",
       " 0.4319060742855072,\n",
       " 0.5036275386810303,\n",
       " 0.5382791757583618,\n",
       " 0.5731017589569092,\n",
       " 0.6721858978271484,\n",
       " 0.6550880670547485,\n",
       " 0.5324430465698242,\n",
       " 0.5149796009063721,\n",
       " 0.5910705327987671,\n",
       " 0.6461492776870728,\n",
       " 0.5055290460586548,\n",
       " 0.45347705483436584,\n",
       " 0.5390981435775757,\n",
       " 0.5158787965774536,\n",
       " 0.6370501518249512,\n",
       " 0.5939291715621948,\n",
       " 0.5945863723754883,\n",
       " 0.454840749502182,\n",
       " 0.5241515636444092,\n",
       " 0.48535802960395813,\n",
       " 0.7620522975921631,\n",
       " 0.6718275547027588,\n",
       " 0.578071117401123,\n",
       " 0.5182846784591675,\n",
       " 0.6725680828094482,\n",
       " 0.5319197773933411,\n",
       " 0.5333040356636047,\n",
       " 0.5529943704605103,\n",
       " 0.5023229122161865,\n",
       " 0.5884549617767334,\n",
       " 0.5068346261978149,\n",
       " 0.5238074064254761,\n",
       " 0.5849360227584839,\n",
       " 0.5429211854934692,\n",
       " 0.4755534827709198,\n",
       " 0.48228728771209717,\n",
       " 0.7137823104858398,\n",
       " 0.5167887210845947,\n",
       " 0.5717456936836243,\n",
       " 0.5168857574462891,\n",
       " 0.5640501976013184,\n",
       " 0.5430006980895996,\n",
       " 0.5042842626571655,\n",
       " 0.6113084554672241,\n",
       " 0.4976751208305359,\n",
       " 0.48434847593307495,\n",
       " 0.6030412912368774,\n",
       " 0.5511907339096069,\n",
       " 0.4788198173046112,\n",
       " 0.4125426113605499,\n",
       " 0.6530762910842896,\n",
       " 0.6274268627166748,\n",
       " 0.5399252772331238,\n",
       " 0.5059748888015747,\n",
       " 0.5907883644104004,\n",
       " 0.4259263575077057,\n",
       " 0.5376628637313843,\n",
       " 0.6426278352737427,\n",
       " 0.5778758525848389,\n",
       " 0.41371965408325195,\n",
       " 0.5433119535446167,\n",
       " 0.4992867410182953,\n",
       " 0.6581780910491943,\n",
       " 0.5330511331558228,\n",
       " 0.5641241073608398,\n",
       " 0.46887707710266113,\n",
       " 0.431437611579895,\n",
       " 0.595941424369812,\n",
       " 0.6467366218566895,\n",
       " 0.500487208366394,\n",
       " 0.4966370165348053,\n",
       " 0.5351112484931946,\n",
       " 0.5676730871200562,\n",
       " 0.5087682008743286,\n",
       " 0.5034977197647095,\n",
       " 0.5360949039459229,\n",
       " 0.5965193510055542,\n",
       " 0.4472281038761139,\n",
       " 0.5555446147918701,\n",
       " 0.5051876306533813,\n",
       " 0.5735049247741699,\n",
       " 0.6453423500061035,\n",
       " 0.4806187152862549,\n",
       " 0.43696579337120056,\n",
       " 0.5792987942695618,\n",
       " 0.4437466859817505,\n",
       " 0.5284692645072937,\n",
       " 0.5539920330047607,\n",
       " 0.6163393259048462,\n",
       " 0.4233971834182739,\n",
       " 0.5121370553970337,\n",
       " 0.6035585403442383,\n",
       " 0.5340143442153931,\n",
       " 0.5848472118377686,\n",
       " 0.4617759883403778,\n",
       " 0.5008199214935303,\n",
       " 0.6719144582748413,\n",
       " 0.5013865232467651,\n",
       " 0.43715450167655945,\n",
       " 0.6256684064865112,\n",
       " 0.5141376256942749,\n",
       " 0.3854082524776459,\n",
       " 0.45301347970962524,\n",
       " 0.6122323274612427,\n",
       " 0.4618507921695709,\n",
       " 0.40271124243736267,\n",
       " 0.5019571781158447,\n",
       " 0.4548085927963257,\n",
       " 0.5033485889434814,\n",
       " 0.6010019779205322,\n",
       " 0.5819734334945679,\n",
       " 0.4476744532585144,\n",
       " 0.5611624717712402,\n",
       " 0.5374596118927002,\n",
       " 0.5344870686531067,\n",
       " 0.5009602308273315,\n",
       " 0.43006816506385803,\n",
       " 0.5653066635131836,\n",
       " 0.4451087713241577,\n",
       " 0.7228425741195679,\n",
       " 0.5819265842437744,\n",
       " 0.5224611759185791,\n",
       " 0.5766159296035767,\n",
       " 0.5839633941650391,\n",
       " 0.5634104013442993,\n",
       " 0.519719660282135,\n",
       " 0.4771265983581543,\n",
       " 0.5240570902824402,\n",
       " 0.4883534610271454,\n",
       " 0.49008938670158386,\n",
       " 0.5396685600280762,\n",
       " 0.5303482413291931,\n",
       " 0.557171106338501,\n",
       " 0.5490295886993408,\n",
       " 0.5135063529014587,\n",
       " 0.4930613338947296,\n",
       " 0.5085315704345703,\n",
       " 0.4410044550895691,\n",
       " 0.5677490234375,\n",
       " 0.5458620190620422,\n",
       " 0.579323410987854,\n",
       " 0.5011751651763916,\n",
       " 0.6225080490112305,\n",
       " 0.5332892537117004,\n",
       " 0.5504889488220215,\n",
       " 0.4576949179172516,\n",
       " 0.5324613451957703,\n",
       " 0.5807299017906189,\n",
       " 0.40746089816093445,\n",
       " 0.4437287151813507,\n",
       " 0.46807190775871277,\n",
       " 0.4579303562641144,\n",
       " 0.47837814688682556,\n",
       " 0.5032668113708496,\n",
       " 0.6448922157287598,\n",
       " 0.4923454225063324,\n",
       " 0.5402590036392212,\n",
       " 0.5965216159820557,\n",
       " 0.43961095809936523,\n",
       " 0.48189881443977356,\n",
       " 0.7710069417953491,\n",
       " 0.5050923228263855,\n",
       " 0.47710996866226196,\n",
       " 0.4647417962551117,\n",
       " 0.6517379283905029,\n",
       " 0.5119771361351013,\n",
       " 0.4378776550292969,\n",
       " 0.6321653127670288,\n",
       " 0.5615867376327515,\n",
       " 0.49732500314712524,\n",
       " 0.6439708471298218,\n",
       " 0.6403933763504028,\n",
       " 0.6224863529205322,\n",
       " 0.7540982961654663,\n",
       " 0.6077070236206055,\n",
       " 0.444060355424881,\n",
       " 0.5389727354049683,\n",
       " 0.538894772529602,\n",
       " 0.5272053480148315,\n",
       " 0.5033236742019653,\n",
       " 0.4890979826450348,\n",
       " 0.656334638595581,\n",
       " 0.5048531889915466,\n",
       " 0.4422321021556854,\n",
       " 0.5859240293502808,\n",
       " 0.8112683296203613,\n",
       " 0.5166044235229492,\n",
       " 0.5749667882919312,\n",
       " 0.547142505645752,\n",
       " 0.5669847726821899,\n",
       " 0.6711773872375488,\n",
       " 0.5801782608032227,\n",
       " 0.6348743438720703,\n",
       " 0.5168625712394714,\n",
       " 0.5180103778839111,\n",
       " 0.4806731939315796,\n",
       " 0.5980088710784912,\n",
       " 0.4582274556159973,\n",
       " 0.4811597168445587,\n",
       " 0.5057835578918457,\n",
       " 0.5011265277862549,\n",
       " 0.4531949460506439,\n",
       " 0.5247365236282349,\n",
       " 0.4544515311717987,\n",
       " 0.6563595533370972,\n",
       " 0.5325775146484375,\n",
       " 0.6274316310882568,\n",
       " 0.7220050096511841,\n",
       " 0.5332624912261963,\n",
       " 0.42933669686317444,\n",
       " 0.5130813121795654,\n",
       " 0.5468980073928833,\n",
       " 0.4519588351249695,\n",
       " 0.5100196599960327,\n",
       " 0.48856955766677856,\n",
       " 0.4632459580898285,\n",
       " 0.5296106338500977,\n",
       " 0.48955869674682617,\n",
       " 0.4926677346229553,\n",
       " 0.6433377265930176,\n",
       " 0.4716506898403168,\n",
       " 0.5440884828567505,\n",
       " 0.48999515175819397,\n",
       " 0.7821204662322998,\n",
       " 0.4424665570259094,\n",
       " 0.5788431167602539,\n",
       " 0.6656938791275024,\n",
       " 0.6375703811645508,\n",
       " 0.5519859194755554,\n",
       " 0.5237206220626831,\n",
       " 0.4727087616920471,\n",
       " 0.5343461036682129,\n",
       " 0.5894330739974976,\n",
       " 0.6172866821289062,\n",
       " 0.5010422468185425,\n",
       " 0.5229448676109314,\n",
       " 0.5487052202224731,\n",
       " 0.4847446382045746,\n",
       " 0.5940924882888794,\n",
       " 0.5200634598731995,\n",
       " 0.6276288032531738,\n",
       " 0.6120152473449707,\n",
       " 0.4659320116043091,\n",
       " 0.5053888559341431,\n",
       " 0.5533530712127686,\n",
       " 0.5655075311660767,\n",
       " 0.4889470040798187,\n",
       " 0.5275548696517944,\n",
       " 0.6509464979171753,\n",
       " 0.5353525280952454,\n",
       " 0.6464124917984009,\n",
       " 0.4949643909931183,\n",
       " 0.6426262855529785,\n",
       " 0.5080999135971069,\n",
       " 0.6183719635009766,\n",
       " 0.7292903661727905,\n",
       " 0.5440641641616821,\n",
       " 0.8621745109558105,\n",
       " 0.6313521862030029,\n",
       " 0.5277283191680908,\n",
       " 0.5430985689163208,\n",
       " 0.43873679637908936,\n",
       " 0.5496743321418762,\n",
       " 0.5348312854766846,\n",
       " 0.4373306930065155,\n",
       " 0.5335851907730103,\n",
       " 0.4747357666492462,\n",
       " 0.5058740377426147,\n",
       " 0.434628427028656,\n",
       " 0.5140677094459534,\n",
       " 0.4719511568546295,\n",
       " 0.449903279542923,\n",
       " 0.48388394713401794,\n",
       " 0.581082820892334,\n",
       " 0.4865151345729828,\n",
       " 0.5281915664672852,\n",
       " 0.6350477933883667,\n",
       " 0.4838891625404358,\n",
       " 0.4813132882118225,\n",
       " 0.5699108242988586,\n",
       " 0.5053489208221436,\n",
       " 0.538982629776001,\n",
       " 0.502540111541748,\n",
       " 0.5504258871078491,\n",
       " 0.5671318769454956,\n",
       " 0.49997055530548096,\n",
       " 0.615164041519165,\n",
       " 0.5458598732948303,\n",
       " 0.4982229471206665,\n",
       " 0.6993408203125,\n",
       " 0.46413856744766235,\n",
       " 0.5279397964477539,\n",
       " 0.65163254737854,\n",
       " 0.533545196056366,\n",
       " 0.5471570491790771,\n",
       " 0.4560762047767639,\n",
       " 0.5827025175094604,\n",
       " 0.5360296964645386,\n",
       " 0.5386989712715149,\n",
       " 0.5330216884613037,\n",
       " 0.5913108587265015,\n",
       " 0.5070109963417053,\n",
       " 0.6608242988586426,\n",
       " 0.5934649705886841,\n",
       " 0.4983573853969574,\n",
       " 0.510669469833374,\n",
       " 0.4909302294254303,\n",
       " 0.5601369142532349,\n",
       " 0.5159050226211548,\n",
       " 0.42016395926475525,\n",
       " 0.5363171100616455,\n",
       " 0.40598809719085693,\n",
       " 0.6859511137008667,\n",
       " 0.5654619932174683,\n",
       " 0.6997026205062866,\n",
       " 0.5595137476921082,\n",
       " 0.46801137924194336,\n",
       " 0.4964159429073334,\n",
       " 0.46682706475257874,\n",
       " 0.4765256345272064,\n",
       " 0.5662648677825928,\n",
       " 0.45220914483070374,\n",
       " 0.5098618865013123,\n",
       " 0.50493323802948,\n",
       " 0.5273985862731934,\n",
       " 0.576238214969635,\n",
       " 0.5613366365432739,\n",
       " 0.5653817057609558,\n",
       " 0.6280761957168579,\n",
       " 0.5598466396331787,\n",
       " 0.5277470350265503,\n",
       " 0.5010062456130981,\n",
       " 0.6397459506988525,\n",
       " 0.6004554033279419,\n",
       " 0.6318709850311279,\n",
       " 0.63807213306427,\n",
       " 0.47023019194602966,\n",
       " 0.4273129105567932,\n",
       " 0.5221517086029053,\n",
       " 0.5052058696746826,\n",
       " 0.6463805437088013,\n",
       " 0.38312727212905884,\n",
       " 0.49992695450782776,\n",
       " 0.5869382619857788,\n",
       " 0.44157108664512634,\n",
       " 0.5711133480072021,\n",
       " 0.5244580507278442,\n",
       " 0.5185012221336365,\n",
       " 0.5888526439666748,\n",
       " 0.631820559501648,\n",
       " 0.4669080674648285,\n",
       " 0.45020344853401184,\n",
       " 0.49149855971336365,\n",
       " 0.5835282802581787,\n",
       " 0.7138004302978516,\n",
       " 0.5529206991195679,\n",
       " 0.5643469095230103,\n",
       " 0.504810094833374,\n",
       " 0.5135252475738525,\n",
       " 0.6344617605209351,\n",
       " 0.5438275337219238,\n",
       " 0.5795481204986572,\n",
       " 0.4893421530723572,\n",
       " 0.5237009525299072,\n",
       " 0.4642631709575653,\n",
       " 0.5893462300300598,\n",
       " 0.5775548815727234,\n",
       " 0.6030510663986206,\n",
       " 0.5946102142333984,\n",
       " 0.5181580185890198,\n",
       " 0.5161778926849365,\n",
       " 0.5457718372344971,\n",
       " 0.5561119318008423,\n",
       " 0.4735684394836426,\n",
       " 0.591569185256958,\n",
       " 0.573144793510437,\n",
       " 0.7720636129379272,\n",
       " 0.572317898273468,\n",
       " 0.5686262845993042,\n",
       " 0.5513229370117188,\n",
       " 0.5857404470443726,\n",
       " 0.45612820982933044,\n",
       " 0.5753029584884644,\n",
       " 0.5104306936264038,\n",
       " 0.4785805940628052,\n",
       " 0.4566206634044647,\n",
       " 0.6229522228240967,\n",
       " 0.5229973196983337,\n",
       " 0.5850344896316528,\n",
       " 0.393625408411026,\n",
       " 0.4979317784309387,\n",
       " 0.5752280950546265,\n",
       " 0.5974490642547607,\n",
       " 0.48235437273979187,\n",
       " 0.5344921350479126,\n",
       " 0.4354151785373688,\n",
       " 0.4555095136165619,\n",
       " 0.39931926131248474,\n",
       " 0.5889326333999634,\n",
       " 0.5186460018157959,\n",
       " 0.47032788395881653,\n",
       " 0.46680131554603577,\n",
       " 0.8336291313171387,\n",
       " 0.6024419069290161,\n",
       " 0.5249224901199341,\n",
       " 0.5343804359436035,\n",
       " 0.617973804473877,\n",
       " 0.657252311706543,\n",
       " 0.5289931893348694,\n",
       " 0.5800893306732178,\n",
       " 0.44657957553863525,\n",
       " 0.4577174484729767,\n",
       " 0.5445477962493896,\n",
       " 0.4475524127483368,\n",
       " 0.5250877737998962,\n",
       " 0.466439813375473,\n",
       " 0.42073771357536316,\n",
       " 0.586841344833374,\n",
       " 0.5419398546218872,\n",
       " 0.545012354850769,\n",
       " 0.4878001809120178,\n",
       " 0.6272972822189331,\n",
       " 0.48485732078552246,\n",
       " 0.6177680492401123,\n",
       " 0.6120270490646362,\n",
       " 0.4416475296020508,\n",
       " 0.5561131238937378,\n",
       " 0.5071982145309448,\n",
       " 0.5144742727279663,\n",
       " 0.5213336944580078,\n",
       " 0.5315756797790527,\n",
       " 0.5750535726547241,\n",
       " 0.47267264127731323,\n",
       " 0.49555009603500366,\n",
       " 0.5488155484199524,\n",
       " 0.4573459029197693,\n",
       " 0.5168969631195068,\n",
       " 0.6274737119674683,\n",
       " 0.5172489881515503,\n",
       " 0.7092796564102173,\n",
       " 0.5451533794403076,\n",
       " 0.6727941036224365,\n",
       " 0.5694534778594971,\n",
       " 0.5197097063064575,\n",
       " 0.5425174236297607,\n",
       " 0.48179301619529724,\n",
       " 0.5988810062408447,\n",
       " 0.6732776165008545,\n",
       " 0.5393151044845581,\n",
       " 0.5181261301040649,\n",
       " 0.5135846138000488,\n",
       " 0.4677196443080902,\n",
       " 0.5211951732635498,\n",
       " 0.4977266788482666,\n",
       " 0.5202556848526001,\n",
       " 0.5915728807449341,\n",
       " 0.5085339546203613,\n",
       " 0.46872496604919434,\n",
       " 0.5956910848617554,\n",
       " 0.5943633317947388,\n",
       " 0.5949809551239014,\n",
       " 0.6455769538879395,\n",
       " 0.6046029329299927,\n",
       " 0.4884740114212036,\n",
       " 0.4993806481361389,\n",
       " 0.5781325101852417,\n",
       " 0.5241333246231079,\n",
       " 0.4848455488681793,\n",
       " 0.5152108669281006,\n",
       " 0.5235309600830078,\n",
       " 0.6311662197113037,\n",
       " 0.5232030153274536,\n",
       " 0.46563395857810974,\n",
       " 0.6118510961532593,\n",
       " 0.5279616117477417,\n",
       " 0.47858354449272156,\n",
       " 0.5047934055328369,\n",
       " 0.6628334522247314,\n",
       " 0.6064039468765259,\n",
       " 0.4123060405254364,\n",
       " 0.627943754196167,\n",
       " 0.6101711988449097,\n",
       " 0.6130508184432983,\n",
       " 0.5722655057907104,\n",
       " 0.5127159953117371,\n",
       " 0.5418354272842407,\n",
       " 0.5468270778656006,\n",
       " 0.6224002838134766,\n",
       " 0.44038423895835876,\n",
       " 0.5710312128067017,\n",
       " 0.5448156595230103,\n",
       " 0.46834322810173035,\n",
       " 0.5673730969429016,\n",
       " 0.47519615292549133,\n",
       " 0.46109190583229065,\n",
       " 0.5413604974746704,\n",
       " 0.49983179569244385,\n",
       " 0.5428833365440369,\n",
       " 0.453116774559021,\n",
       " 0.6060729026794434,\n",
       " 0.4849187731742859,\n",
       " 0.48821014165878296,\n",
       " 0.4672730565071106,\n",
       " 0.5369760990142822,\n",
       " 0.5705232620239258,\n",
       " 0.5337609052658081,\n",
       " 0.5407498478889465,\n",
       " 0.6599096059799194,\n",
       " 0.661725640296936,\n",
       " 0.4395386278629303,\n",
       " 0.4744768738746643,\n",
       " 0.45125019550323486,\n",
       " 0.5490504503250122,\n",
       " 0.5934479236602783,\n",
       " 0.4202500879764557,\n",
       " 0.5811777710914612,\n",
       " 0.5058778524398804,\n",
       " 0.5780748128890991,\n",
       " 0.4458003640174866,\n",
       " 0.5176749229431152,\n",
       " 0.45081835985183716,\n",
       " 0.5935941934585571,\n",
       " 0.512047529220581,\n",
       " 0.5092858076095581,\n",
       " 0.4290245771408081,\n",
       " 0.5242654085159302,\n",
       " 0.5969579219818115,\n",
       " 0.5420101881027222,\n",
       " 0.6414687633514404,\n",
       " 0.7378076314926147,\n",
       " 0.47481581568717957,\n",
       " 0.5422346591949463,\n",
       " 0.5296792984008789,\n",
       " 0.5104079246520996,\n",
       " 0.5214848518371582,\n",
       " 0.45282402634620667,\n",
       " 0.6575980186462402,\n",
       " 0.5372794270515442,\n",
       " 0.5342704653739929,\n",
       " 0.5111212730407715,\n",
       " 0.7369046211242676,\n",
       " 0.7089273929595947,\n",
       " 0.5773711204528809,\n",
       " 0.6526131629943848,\n",
       " 0.5855284333229065,\n",
       " 0.4414953887462616,\n",
       " 0.4591163992881775,\n",
       " 0.4523344933986664,\n",
       " 0.5878411531448364,\n",
       " 0.732008695602417,\n",
       " 0.5411065816879272,\n",
       " 0.7102159261703491,\n",
       " 0.4695395529270172,\n",
       " 0.582253098487854,\n",
       " 0.8613278865814209,\n",
       " 0.5143927931785583,\n",
       " 0.6143864393234253,\n",
       " 0.554059624671936,\n",
       " 0.6155253648757935,\n",
       " 0.5711086392402649,\n",
       " 0.5094964504241943,\n",
       " 0.4624074697494507,\n",
       " 0.5500137209892273,\n",
       " 0.5182340741157532,\n",
       " 0.5680455565452576,\n",
       " 0.6321960687637329,\n",
       " 0.5787849426269531,\n",
       " 0.5914561748504639,\n",
       " 0.6042766571044922,\n",
       " 0.6029238700866699,\n",
       " 0.6194266080856323,\n",
       " 0.5638981461524963,\n",
       " 0.45440590381622314,\n",
       " 0.5601328611373901,\n",
       " 0.6049277782440186,\n",
       " 0.5886011123657227,\n",
       " 0.5071151256561279,\n",
       " 0.5532079935073853,\n",
       " 0.40346845984458923,\n",
       " 0.6321210861206055,\n",
       " 0.44817259907722473,\n",
       " 0.47902897000312805,\n",
       " 0.61832594871521,\n",
       " 0.5137408971786499,\n",
       " 0.46499279141426086,\n",
       " 0.48732510209083557,\n",
       " 0.4800424873828888,\n",
       " 0.576913595199585,\n",
       " 0.5721499919891357,\n",
       " 0.5456236600875854,\n",
       " 0.6607682704925537,\n",
       " 0.564868688583374,\n",
       " 0.525837779045105,\n",
       " 0.5632805824279785,\n",
       " 0.5284278392791748,\n",
       " 0.5119212865829468,\n",
       " 0.5457416772842407,\n",
       " 0.4945860505104065,\n",
       " 0.5159389972686768,\n",
       " 0.48973721265792847,\n",
       " 0.5078911781311035,\n",
       " 0.5409243106842041,\n",
       " 0.5312042236328125,\n",
       " 0.5843992233276367,\n",
       " 0.5283070802688599,\n",
       " 0.6070255041122437,\n",
       " 0.5236472487449646,\n",
       " 0.4715196192264557,\n",
       " 0.3753204941749573,\n",
       " 0.5727063417434692,\n",
       " 0.4344641864299774,\n",
       " 0.4973525106906891,\n",
       " 0.6222621202468872,\n",
       " 0.4702799916267395,\n",
       " 0.7560296058654785,\n",
       " 0.533954918384552,\n",
       " 0.3785169720649719,\n",
       " 0.4466291069984436,\n",
       " 0.5226422548294067,\n",
       " 0.576018214225769,\n",
       " 0.5006829500198364,\n",
       " 0.5038756132125854,\n",
       " 0.42281389236450195,\n",
       " 0.6373254060745239,\n",
       " 0.5654453039169312,\n",
       " 0.727319598197937,\n",
       " 0.49103644490242004,\n",
       " 0.482150137424469,\n",
       " 0.559463381767273,\n",
       " 0.47497597336769104,\n",
       " 0.5667707920074463,\n",
       " 0.6520470380783081,\n",
       " 0.6300227642059326,\n",
       " 0.55515056848526,\n",
       " 0.531693696975708,\n",
       " 0.44905486702919006,\n",
       " 0.5918276309967041,\n",
       " 0.43592387437820435,\n",
       " 0.5021495819091797,\n",
       " 0.6850091218948364,\n",
       " 0.5993194580078125,\n",
       " 0.5306446552276611,\n",
       " 0.4018948972225189,\n",
       " 0.4866410195827484,\n",
       " 0.5240349769592285,\n",
       " 0.527969479560852,\n",
       " 0.5166946649551392,\n",
       " 0.5160757303237915,\n",
       " 0.5365654826164246,\n",
       " 0.556230902671814,\n",
       " 0.5643929243087769,\n",
       " 0.4974983334541321,\n",
       " 0.5287257432937622,\n",
       " 0.48695996403694153,\n",
       " 0.4876720607280731,\n",
       " 0.5112828016281128,\n",
       " 0.46450483798980713,\n",
       " 0.4505273997783661,\n",
       " 0.6163926124572754,\n",
       " 0.5647869110107422,\n",
       " 0.5208216309547424,\n",
       " 0.5481816530227661,\n",
       " 0.594093918800354,\n",
       " 0.5687857866287231,\n",
       " 0.41531649231910706,\n",
       " 0.6413165330886841,\n",
       " 0.6172212362289429,\n",
       " 0.6219251155853271,\n",
       " 0.4811559021472931,\n",
       " 0.4667162001132965,\n",
       " 0.4816966950893402,\n",
       " 0.6141167879104614,\n",
       " 0.4542933404445648,\n",
       " 0.560675859451294,\n",
       " 0.5328857898712158,\n",
       " 0.514717698097229,\n",
       " 0.562746524810791,\n",
       " 0.5202059149742126,\n",
       " 0.5123208165168762,\n",
       " 0.5159540176391602,\n",
       " 0.41451627016067505,\n",
       " 0.508039116859436,\n",
       " 0.4350738823413849,\n",
       " 0.5681089758872986,\n",
       " 0.6299921274185181,\n",
       " 0.4351808428764343,\n",
       " 0.5438022613525391,\n",
       " 0.5162606835365295,\n",
       " 0.44370636343955994,\n",
       " 0.4676462411880493,\n",
       " 0.5771297216415405,\n",
       " 0.46367523074150085,\n",
       " 0.47115835547447205,\n",
       " 0.5305836200714111,\n",
       " 0.6203153133392334,\n",
       " 0.6026626825332642,\n",
       " 0.546959400177002,\n",
       " 0.5278811454772949,\n",
       " 0.5455560684204102,\n",
       " 0.5103298425674438,\n",
       " 0.5753989219665527,\n",
       " 0.48228415846824646,\n",
       " 0.5390372276306152,\n",
       " 0.5244665145874023,\n",
       " 0.5314244031906128,\n",
       " 0.48960745334625244,\n",
       " 0.6087156534194946,\n",
       " 0.5655062198638916,\n",
       " 0.4644058048725128,\n",
       " 0.4951322078704834,\n",
       " 0.44710952043533325,\n",
       " 0.5167576670646667,\n",
       " 0.6485792398452759,\n",
       " 0.5208865404129028,\n",
       " 0.5112253427505493,\n",
       " 0.5514465570449829,\n",
       " 0.521338701248169,\n",
       " 0.5080811977386475,\n",
       " 0.50605309009552,\n",
       " 0.46840205788612366,\n",
       " 0.44314494729042053,\n",
       " 0.46719783544540405,\n",
       " 0.5489529371261597,\n",
       " 0.5502575039863586,\n",
       " 0.4851635694503784,\n",
       " 0.5264612436294556,\n",
       " 0.5553568601608276,\n",
       " 0.5012096166610718,\n",
       " 0.47374090552330017,\n",
       " 0.47807174921035767,\n",
       " 0.4980631172657013,\n",
       " 0.6359274387359619,\n",
       " 0.6546145677566528,\n",
       " 0.49748697876930237,\n",
       " 0.4791482388973236,\n",
       " 0.5609290599822998,\n",
       " 0.5027710199356079,\n",
       " 0.4721939265727997,\n",
       " 0.5016878843307495,\n",
       " 0.5680270195007324,\n",
       " 0.4463895261287689,\n",
       " 0.6194900274276733,\n",
       " 0.5426511764526367,\n",
       " 0.5015333890914917,\n",
       " 0.4580290913581848,\n",
       " 0.5247200131416321,\n",
       " 0.5404624938964844,\n",
       " 0.5528711080551147,\n",
       " 0.47540605068206787,\n",
       " 0.5069025754928589,\n",
       " 0.60621178150177,\n",
       " 0.49595504999160767,\n",
       " 0.5878998041152954,\n",
       " 0.41730549931526184,\n",
       " 0.4961121082305908,\n",
       " 0.47147831320762634,\n",
       " 0.5520593523979187,\n",
       " 0.5280600786209106,\n",
       " 0.4973660111427307,\n",
       " 0.4982658922672272,\n",
       " 0.39375635981559753,\n",
       " 0.5182832479476929,\n",
       " 0.5095546245574951,\n",
       " 0.6596710681915283,\n",
       " 0.5199551582336426,\n",
       " 0.5084027051925659,\n",
       " 0.5056986808776855,\n",
       " 0.5139515399932861,\n",
       " 0.573204755783081,\n",
       " 0.4802496135234833,\n",
       " 0.6931583881378174,\n",
       " 0.5002881288528442,\n",
       " 0.7570688724517822,\n",
       " 0.5466124415397644,\n",
       " 0.403650164604187,\n",
       " 0.5523133873939514,\n",
       " 0.4598119854927063,\n",
       " 0.4619622826576233,\n",
       " 0.515238881111145,\n",
       " 0.5083317160606384,\n",
       " 0.7411633729934692,\n",
       " 0.5206130743026733,\n",
       " 0.4221895635128021,\n",
       " 0.6016229391098022,\n",
       " 0.5727572441101074,\n",
       " 0.5710726976394653,\n",
       " 0.5373990535736084,\n",
       " 0.4993288516998291,\n",
       " 0.5723487734794617,\n",
       " 0.5567653179168701,\n",
       " 0.5606740713119507,\n",
       " 0.5144139528274536,\n",
       " 0.42084142565727234,\n",
       " 0.4495398700237274,\n",
       " 0.48414650559425354,\n",
       " 0.5856277942657471,\n",
       " 0.5763989686965942,\n",
       " 0.5298540592193604,\n",
       " 0.5318230390548706,\n",
       " 0.5315825939178467,\n",
       " 0.730715274810791,\n",
       " 0.6150436401367188,\n",
       " 0.6977192163467407,\n",
       " 0.4521356523036957,\n",
       " 0.4522959887981415,\n",
       " 0.5058712959289551,\n",
       " 0.46483802795410156,\n",
       " 0.504828691482544,\n",
       " 0.5660184621810913,\n",
       " 0.5354732275009155,\n",
       " 0.6281123161315918,\n",
       " 0.5155587196350098,\n",
       " 0.4796895980834961,\n",
       " 0.5233607292175293,\n",
       " 0.6283031702041626,\n",
       " 0.5266138315200806,\n",
       " 0.5547294616699219,\n",
       " 0.5294418334960938,\n",
       " 0.5074609518051147,\n",
       " 0.6184793710708618,\n",
       " 0.6283715963363647,\n",
       " 0.5183771848678589,\n",
       " 0.426524817943573,\n",
       " 0.554449200630188,\n",
       " 0.5320228338241577,\n",
       " 0.5645852088928223,\n",
       " 0.4361549913883209,\n",
       " 0.625923752784729,\n",
       " 0.4099935293197632,\n",
       " 0.5144680738449097,\n",
       " 0.5277949571609497,\n",
       " 0.6713004112243652,\n",
       " 0.6101399660110474,\n",
       " 0.6704047918319702,\n",
       " 0.45929521322250366,\n",
       " 0.5612665414810181,\n",
       " 0.5842078924179077,\n",
       " 0.46801674365997314,\n",
       " 0.5478312373161316,\n",
       " 0.5201162099838257,\n",
       " 0.6040831804275513,\n",
       " 0.5791349411010742,\n",
       " 0.46472129225730896,\n",
       " 0.5109885931015015,\n",
       " 0.6601824760437012,\n",
       " 0.5758674144744873,\n",
       " 0.5091549158096313,\n",
       " 0.5125671625137329,\n",
       " 0.5934090614318848,\n",
       " 0.5446242094039917,\n",
       " 0.5446431636810303,\n",
       " 0.44582605361938477,\n",
       " 0.5779814720153809,\n",
       " 0.5529835224151611,\n",
       " 0.5733788013458252,\n",
       " 0.4909500777721405,\n",
       " 0.5408118963241577,\n",
       " 0.4335760772228241,\n",
       " 0.4401603043079376,\n",
       " 0.4873614013195038,\n",
       " 0.5080816745758057,\n",
       " 0.49290451407432556,\n",
       " 0.5069137811660767,\n",
       " 0.471772700548172,\n",
       " 0.4846644103527069,\n",
       " 0.48443007469177246,\n",
       " 0.47043469548225403,\n",
       " 0.5024261474609375,\n",
       " 0.4943622648715973,\n",
       " 0.4285696744918823,\n",
       " 0.5586289167404175,\n",
       " 0.5162210464477539,\n",
       " 0.602789044380188,\n",
       " 0.4679415225982666,\n",
       " 0.5678844451904297,\n",
       " 0.6040928363800049,\n",
       " 0.4727911353111267,\n",
       " 0.5599912405014038,\n",
       " 0.4969331920146942,\n",
       " 0.49649903178215027,\n",
       " 0.4062430262565613,\n",
       " 0.5784416198730469,\n",
       " 0.5141355991363525,\n",
       " 0.5914347171783447,\n",
       " 0.48955610394477844,\n",
       " 0.4646303057670593,\n",
       " 0.527579665184021,\n",
       " 0.4700738489627838,\n",
       " 0.5519251823425293,\n",
       " 0.6392412185668945,\n",
       " 0.5414605140686035,\n",
       " 0.5006263256072998,\n",
       " 0.5625371932983398,\n",
       " 0.5418727993965149,\n",
       " 0.574852705001831,\n",
       " 0.7081859111785889,\n",
       " 0.5916053056716919,\n",
       " 0.4719442129135132,\n",
       " 0.43160831928253174,\n",
       " 0.6154506206512451,\n",
       " 0.4631943106651306,\n",
       " 0.42844825983047485,\n",
       " 0.5497655868530273,\n",
       " 0.6573091745376587,\n",
       " 0.5626907348632812,\n",
       " 0.44533905386924744,\n",
       " 0.42763349413871765,\n",
       " 0.5290936231613159,\n",
       " 0.440177321434021,\n",
       " 0.6711410284042358,\n",
       " 0.6180973052978516,\n",
       " 0.5575501918792725,\n",
       " 0.601707935333252,\n",
       " 0.5600168704986572,\n",
       " 0.4913988411426544,\n",
       " 0.5820823311805725,\n",
       " 0.6136574745178223,\n",
       " 0.6754224300384521,\n",
       " 0.5225983262062073,\n",
       " 0.4476361870765686,\n",
       " 0.5532493591308594,\n",
       " 0.6125720739364624,\n",
       " 0.6175655126571655,\n",
       " 0.5604619979858398,\n",
       " 0.5676746368408203,\n",
       " 0.46695613861083984,\n",
       " 0.6710293292999268,\n",
       " 0.5244238376617432,\n",
       " 0.5060857534408569,\n",
       " 0.4854581654071808,\n",
       " 0.45910125970840454,\n",
       " 0.5255700349807739,\n",
       " 0.677381157875061,\n",
       " 0.5966684818267822,\n",
       " 0.5283653736114502,\n",
       " 0.505422055721283,\n",
       " 0.4789821207523346,\n",
       " 0.479383260011673,\n",
       " 0.5525088310241699,\n",
       " 0.5172963738441467,\n",
       " 0.46179690957069397,\n",
       " 0.5902040004730225,\n",
       " 0.5724643468856812,\n",
       " 0.46736446022987366,\n",
       " 0.4916377365589142,\n",
       " 0.5644826889038086,\n",
       " 0.4934639632701874,\n",
       " 0.6301137208938599,\n",
       " 0.4711531698703766,\n",
       " 0.5762062072753906,\n",
       " 0.49836406111717224,\n",
       " 0.5057395696640015,\n",
       " 0.4629030227661133,\n",
       " 0.4388226866722107,\n",
       " 0.47485554218292236,\n",
       " 0.6616599559783936,\n",
       " 0.4757305979728699,\n",
       " 0.6245306730270386,\n",
       " 0.4387909471988678,\n",
       " 0.5021464228630066,\n",
       " 0.48672762513160706,\n",
       " 0.5101271271705627,\n",
       " 0.5205211639404297,\n",
       " 0.6203995943069458,\n",
       " 0.49613818526268005,\n",
       " 0.5208637714385986,\n",
       " 0.6295129060745239,\n",
       " 0.554336667060852,\n",
       " 0.5987973213195801,\n",
       " 0.4995677173137665,\n",
       " 0.43607068061828613,\n",
       " 0.5048189163208008,\n",
       " 0.46339017152786255,\n",
       " 0.41585204005241394,\n",
       " 0.5819594264030457,\n",
       " 0.658612847328186,\n",
       " 0.5480906963348389,\n",
       " 0.49970003962516785,\n",
       " 0.5034568309783936,\n",
       " 0.5980732440948486,\n",
       " 0.5276939868927002,\n",
       " 0.6052381992340088,\n",
       " 0.7007510662078857,\n",
       " 0.48101338744163513,\n",
       " 0.5207092761993408,\n",
       " 0.5358946323394775,\n",
       " 0.4810294806957245,\n",
       " 0.5087798833847046,\n",
       " 0.6298929452896118,\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77681409-0774-4107-a4e1-911bbd81191e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs_binary = (np.array(test_outputs) > 0.5).astype(int)\n",
    "test_outputs_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b961ace-068c-42d1-a77f-55d4f4be1647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6104"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_outputs_binary == test_true_labels).sum() / len(test_true_labels) #accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc84378-8ce0-41ee-92d6-f30d438ccf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6db97-9909-461a-a61d-8f512f62fae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42677e01-05c6-4990-846d-2bbea65df787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ce656-3320-43d1-b8cb-dd5dde625368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e844d9-32ab-43f5-a8e4-81974ae63cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f2836-c963-434d-b22c-092c3e3ddf83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5d7fe-2ed5-4356-990f-19f7a34a74f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367650a0-f801-4d27-8929-abbae7f1dc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac7c10-14fe-426b-b3c0-70534f8b364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resume Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121aee4-c33c-4c3a-84d8-df568a6711f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598f1a0-fcb1-4381-9446-8bb6298e3e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b8f8eb-2979-4d6a-8e90-f0c0550113ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef69c1-de39-4090-a87f-fbeac1e68942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634dd71-416d-4216-8a2e-aa29c73c7a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfca564-5f1c-4de3-8858-83d3946cdc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conda create -n torch_gpu python=3.8 anaconda\n",
    "## conda activate torch_gpu\n",
    "## pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ee783-fa13-440e-a9b3-aa67f4657527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a2b88-bb5c-4d11-bda4-14759da5f681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c43b3-3747-472b-85da-0ec19a70567d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f3b8f87-2e1e-471f-bf50-6799d6680ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6907, device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(torch.unsqueeze(val_output,dim=0),val_labels.type(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad9722-f0f4-4c32-94ad-7e703dc3407b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0546c-c6ca-497c-adbe-2c4401f3e252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b6be3-7085-48db-952b-e01cbd25a676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7f707-430b-4275-8ff0-9ac8a811d910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e7957-9572-4ce2-9c7e-509770ae75fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63657022-1b45-4bf7-947f-2b4855315171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7655fbb2-a54d-4952-93ee-b9ccc146816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33edc293-9c45-458f-a6a1-0dfedb1ca44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.600116  , -0.7715232 , -0.98809004, ..., -0.51925546,\n",
       "          -0.4499052 , -0.35490334],\n",
       "         [-0.8513372 , -0.61788774, -0.8683329 , ..., -0.52104306,\n",
       "          -0.45699853, -0.36221644],\n",
       "         [-0.9254856 , -0.64325154, -0.6304443 , ..., -0.52457213,\n",
       "          -0.46140182, -0.36893332],\n",
       "         ...,\n",
       "         [-0.76769507, -0.7446293 , -0.7324017 , ..., -0.9124992 ,\n",
       "          -0.9696112 , -0.9795303 ],\n",
       "         [-0.73559904, -0.72904885, -0.7033951 , ..., -0.91429484,\n",
       "          -0.9684049 , -0.98730886],\n",
       "         [-0.7249031 , -0.7122105 , -0.7027049 , ..., -0.90359616,\n",
       "          -0.95838463, -0.98961145]],\n",
       "\n",
       "        [[-0.600116  , -0.7715232 , -0.98809004, ..., -0.5035692 ,\n",
       "          -0.43421888, -0.33921707],\n",
       "         [-0.8513372 , -0.61788774, -0.8683329 , ..., -0.5053568 ,\n",
       "          -0.44131222, -0.34653017],\n",
       "         [-0.9254856 , -0.64325154, -0.6304443 , ..., -0.5088858 ,\n",
       "          -0.4457155 , -0.35324705],\n",
       "         ...,\n",
       "         [-0.81475395, -0.7916882 , -0.77946055, ..., -0.9167268 ,\n",
       "          -0.9774543 , -0.98836005],\n",
       "         [-0.78265786, -0.77610767, -0.750454  , ..., -0.9204043 ,\n",
       "          -0.9762481 , -0.99562514],\n",
       "         [-0.7719619 , -0.75926936, -0.7497637 , ..., -0.9114393 ,\n",
       "          -0.96622777, -0.99745464]],\n",
       "\n",
       "        [[-0.600116  , -0.7715232 , -0.98809004, ..., -0.69180447,\n",
       "          -0.6224543 , -0.5274524 ],\n",
       "         [-0.8513372 , -0.61788774, -0.8683329 , ..., -0.693592  ,\n",
       "          -0.6295476 , -0.5347655 ],\n",
       "         [-0.9254856 , -0.64325154, -0.6304443 , ..., -0.69712114,\n",
       "          -0.6339509 , -0.5414824 ],\n",
       "         ...,\n",
       "         [-0.8050191 , -0.78535616, -0.76463234, ..., -0.9667891 ,\n",
       "          -0.9936107 , -0.99031425],\n",
       "         [-0.7669716 , -0.7604214 , -0.73631334, ..., -0.9626206 ,\n",
       "          -0.9951408 , -0.99849975],\n",
       "         [-0.76045877, -0.7441418 , -0.74466306, ..., -0.9464274 ,\n",
       "          -0.9849909 , -0.9972975 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00278081, -0.01832441, -0.02445632, ..., -0.37354723,\n",
       "          -0.3324774 , -0.25276273],\n",
       "         [-0.0013469 , -0.02513146, -0.03242201, ..., -0.31373215,\n",
       "          -0.24637558, -0.17346832],\n",
       "         [-0.00550134, -0.03472706, -0.04544674, ..., -0.24742974,\n",
       "          -0.16299996, -0.10373719],\n",
       "         ...,\n",
       "         [-0.2891466 , -0.27880013, -0.2629556 , ..., -0.04681039,\n",
       "          -0.0993652 , -0.14146818],\n",
       "         [-0.24641486, -0.22543335, -0.22511029, ..., -0.0338759 ,\n",
       "          -0.08001127, -0.10304826],\n",
       "         [-0.26031193, -0.3127863 , -0.31662095, ..., -0.05067626,\n",
       "          -0.06804356, -0.03252602]],\n",
       "\n",
       "        [[-0.31094474, -0.3320499 , -0.34117645, ..., -0.7186453 ,\n",
       "          -0.67757547, -0.5978608 ],\n",
       "         [-0.31507242, -0.33885694, -0.34914213, ..., -0.65883017,\n",
       "          -0.5914737 , -0.51856637],\n",
       "         [-0.31922683, -0.34845254, -0.36216685, ..., -0.5925278 ,\n",
       "          -0.508098  , -0.44883522],\n",
       "         ...,\n",
       "         [-0.4851938 , -0.485606  , -0.47836787, ..., -0.33910984,\n",
       "          -0.37273413, -0.39916193],\n",
       "         [-0.47350484, -0.45264703, -0.45834336, ..., -0.32310942,\n",
       "          -0.35338017, -0.36016706],\n",
       "         [-0.50859624, -0.5610707 , -0.5669173 , ..., -0.33618093,\n",
       "          -0.3342155 , -0.27978972]],\n",
       "\n",
       "        [[-0.5073084 , -0.53368986, -0.5510874 , ..., -0.9460963 ,\n",
       "          -0.90502644, -0.8253118 ],\n",
       "         [-0.51527405, -0.54165554, -0.55905306, ..., -0.88628125,\n",
       "          -0.81892467, -0.74601734],\n",
       "         [-0.52314836, -0.5523741 , -0.5720778 , ..., -0.81997883,\n",
       "          -0.735549  , -0.6762862 ],\n",
       "         ...,\n",
       "         [-0.6159024 , -0.6199009 , -0.61421347, ..., -0.5862578 ,\n",
       "          -0.62071985, -0.64243627],\n",
       "         [-0.614561  , -0.59374446, -0.5994586 , ..., -0.57179034,\n",
       "          -0.6013659 , -0.6037289 ],\n",
       "         [-0.6549811 , -0.7074555 , -0.71330214, ..., -0.574463  ,\n",
       "          -0.5717846 , -0.51293814]]],\n",
       "\n",
       "\n",
       "       [[[-0.30227712, -0.2747685 , -0.2664212 , ...,  0.445238  ,\n",
       "           0.48309153,  0.48215428],\n",
       "         [-0.28374726, -0.26454777, -0.25993642, ...,  0.48502284,\n",
       "           0.5278927 ,  0.52450967],\n",
       "         [-0.29165956, -0.2888806 , -0.29135165, ...,  0.5002321 ,\n",
       "           0.5423399 ,  0.5513178 ],\n",
       "         ...,\n",
       "         [ 0.3101107 ,  0.31862372,  0.32405394, ..., -0.9321449 ,\n",
       "          -0.87938184, -0.833962  ],\n",
       "         [ 0.3136171 ,  0.3218669 ,  0.3280226 , ..., -0.9103874 ,\n",
       "          -0.87174964, -0.82930994],\n",
       "         [ 0.31995603,  0.33735892,  0.3474824 , ..., -0.8519253 ,\n",
       "          -0.83717346, -0.81112516]],\n",
       "\n",
       "        [[-0.14326143, -0.08562449, -0.04958836, ...,  0.5862261 ,\n",
       "           0.62228715,  0.6158055 ],\n",
       "         [-0.13720885, -0.080658  , -0.04310361, ...,  0.63723874,\n",
       "           0.67897785,  0.6699506 ],\n",
       "         [-0.15290041, -0.1064342 , -0.07596223, ...,  0.6681647 ,\n",
       "           0.70936537,  0.70488757],\n",
       "         ...,\n",
       "         [ 0.5008691 ,  0.48980582,  0.4760312 , ..., -0.89660513,\n",
       "          -0.8426301 , -0.8027806 ],\n",
       "         [ 0.51173675,  0.4986413 ,  0.48112485, ..., -0.9127587 ,\n",
       "          -0.8694629 , -0.83026755],\n",
       "         [ 0.5234881 ,  0.51658523,  0.5006646 , ..., -0.8802506 ,\n",
       "          -0.861432  , -0.8363694 ]],\n",
       "\n",
       "        [[ 0.0427973 ,  0.10448824,  0.1400345 , ...,  0.6493225 ,\n",
       "           0.68627983,  0.6821991 ],\n",
       "         [ 0.0510265 ,  0.11208183,  0.14651924, ...,  0.71015036,\n",
       "           0.7524548 ,  0.7456992 ],\n",
       "         [ 0.0375345 ,  0.08527675,  0.11318891, ...,  0.75061923,\n",
       "           0.79206926,  0.7904906 ],\n",
       "         ...,\n",
       "         [ 0.65263444,  0.62620187,  0.59437007, ..., -0.8957957 ,\n",
       "          -0.86257845, -0.8224034 ],\n",
       "         [ 0.6233982 ,  0.61170065,  0.6020571 , ..., -0.91785145,\n",
       "          -0.8974942 , -0.84415   ],\n",
       "         [ 0.6037289 ,  0.6158517 ,  0.62983537, ..., -0.87839955,\n",
       "          -0.8821198 , -0.84076303]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.478044  ,  0.53470933,  0.543645  , ..., -0.2707277 ,\n",
       "          -0.32715362, -0.33349192],\n",
       "         [ 0.4752625 ,  0.52588934,  0.5341021 , ..., -0.2931223 ,\n",
       "          -0.35143852, -0.36315146],\n",
       "         [ 0.46251008,  0.5068767 ,  0.52077305, ..., -0.31180063,\n",
       "          -0.36554638, -0.38454628],\n",
       "         ...,\n",
       "         [-0.19428918, -0.12556404, -0.0466258 , ..., -0.26444525,\n",
       "          -0.29465076, -0.28546858],\n",
       "         [ 0.00982326, -0.1251396 , -0.16918546, ..., -0.2769733 ,\n",
       "          -0.31284463, -0.27361447],\n",
       "         [ 0.6787856 ,  0.64725673,  0.58384615, ..., -0.24410686,\n",
       "          -0.27272153, -0.22049361]],\n",
       "\n",
       "        [[ 0.28196558,  0.32640755,  0.33188036, ..., -0.7099761 ,\n",
       "          -0.7370103 , -0.73985827],\n",
       "         [ 0.27918407,  0.31758755,  0.3223373 , ..., -0.7314729 ,\n",
       "          -0.7480944 , -0.75054187],\n",
       "         [ 0.26643166,  0.29857492,  0.30900836, ..., -0.7484897 ,\n",
       "          -0.7485055 , -0.74914235],\n",
       "         ...,\n",
       "         [-0.3377191 , -0.27055615, -0.18939418, ..., -0.6809345 ,\n",
       "          -0.68090105, -0.6717179 ],\n",
       "         [-0.11404303, -0.2505563 , -0.29239523, ..., -0.6984234 ,\n",
       "          -0.6892182 , -0.63647866],\n",
       "         [ 0.5780637 ,  0.54496896,  0.48378715, ..., -0.67424047,\n",
       "          -0.6490254 , -0.572419  ]],\n",
       "\n",
       "        [[ 0.31333813,  0.36389178,  0.37109604, ..., -0.6409433 ,\n",
       "          -0.6925545 , -0.6974594 ],\n",
       "         [ 0.31055662,  0.3550718 ,  0.36155298, ..., -0.65719074,\n",
       "          -0.704438  , -0.71745294],\n",
       "         [ 0.29780424,  0.33605915,  0.34822404, ..., -0.67467606,\n",
       "          -0.70906025, -0.7243424 ],\n",
       "         ...,\n",
       "         [-0.37821126, -0.30923742, -0.2306532 , ..., -0.7145866 ,\n",
       "          -0.70540106, -0.6829182 ],\n",
       "         [-0.1405997 , -0.27581674, -0.3195007 , ..., -0.74063385,\n",
       "          -0.7208296 , -0.6589074 ],\n",
       "         [ 0.5624258 ,  0.5297518 ,  0.4679712 , ..., -0.71878654,\n",
       "          -0.69140726, -0.6144497 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.405247  , -0.4195341 , -0.47473913, ...,  0.40392157,\n",
       "           0.4039216 ,  0.4133997 ],\n",
       "         [-0.406529  , -0.41274303, -0.46430522, ...,  0.40647537,\n",
       "           0.40647542,  0.4149248 ],\n",
       "         [-0.39190352, -0.39303637, -0.44014418, ...,  0.41592312,\n",
       "           0.41592315,  0.4205668 ],\n",
       "         ...,\n",
       "         [-0.9196396 , -0.93336105, -0.9454831 , ..., -0.14171328,\n",
       "          -0.2696422 , -0.370381  ],\n",
       "         [-0.8815025 , -0.8948146 , -0.8862839 , ..., -0.18547426,\n",
       "          -0.28217772, -0.36967734],\n",
       "         [-0.91915834, -0.9118678 , -0.89316374, ..., -0.20523943,\n",
       "          -0.28195927, -0.3650099 ]],\n",
       "\n",
       "        [[-0.44215742, -0.45691302, -0.5115163 , ...,  0.2313726 ,\n",
       "           0.23137262,  0.24085067],\n",
       "         [-0.45736694, -0.46705586, -0.5141536 , ...,  0.23392639,\n",
       "           0.23392642,  0.24237576],\n",
       "         [-0.4577539 , -0.46250844, -0.50496316, ...,  0.24337411,\n",
       "           0.24337414,  0.24801776],\n",
       "         ...,\n",
       "         [-0.9411483 , -0.9202323 , -0.900558  , ..., -0.21346468,\n",
       "          -0.30870503, -0.38290793],\n",
       "         [-0.9051534 , -0.88579917, -0.8433026 , ..., -0.27016848,\n",
       "          -0.32299912, -0.38220423],\n",
       "         [-0.8738375 , -0.86745226, -0.8418314 , ..., -0.2808737 ,\n",
       "          -0.32021824, -0.36811763]],\n",
       "\n",
       "        [[-0.49080798, -0.5055636 , -0.56016684, ..., -0.06200696,\n",
       "          -0.06200697, -0.05252887],\n",
       "         [-0.5033204 , -0.51241964, -0.56027496, ..., -0.05626974,\n",
       "          -0.05626974, -0.04782036],\n",
       "         [-0.48894262, -0.49188626, -0.5366676 , ..., -0.05199543,\n",
       "          -0.04954697, -0.04714497],\n",
       "         ...,\n",
       "         [-0.9518555 , -0.955702  , -0.95055294, ..., -0.25941777,\n",
       "          -0.2648136 , -0.28560832],\n",
       "         [-0.91008866, -0.92017317, -0.8925209 , ..., -0.30907607,\n",
       "          -0.27822843, -0.28305572],\n",
       "         [-0.896981  , -0.9132092 , -0.8948883 , ..., -0.30906692,\n",
       "          -0.27817294, -0.28591338]]],\n",
       "\n",
       "\n",
       "       [[[ 0.11953695,  0.10668058,  0.0843491 , ..., -0.03642376,\n",
       "          -0.07441903, -0.13576227],\n",
       "         [ 0.12610346,  0.10528553,  0.07505769, ..., -0.02872272,\n",
       "          -0.04635369, -0.13756752],\n",
       "         [ 0.10342054,  0.07380222,  0.04163491, ..., -0.06257917,\n",
       "          -0.09514735, -0.18258774],\n",
       "         ...,\n",
       "         [ 0.3729438 ,  0.4437793 ,  0.54921377, ...,  0.52053046,\n",
       "           0.5106165 ,  0.5227998 ],\n",
       "         [ 0.62752056,  0.6576028 ,  0.65575516, ...,  0.50291675,\n",
       "           0.47633123,  0.4860087 ],\n",
       "         [ 0.6235327 ,  0.65836424,  0.5941582 , ...,  0.5435474 ,\n",
       "           0.52166826,  0.50832236]],\n",
       "\n",
       "        [[ 0.10385066,  0.0909943 ,  0.06866283, ..., -0.05021021,\n",
       "          -0.08869302, -0.14780416],\n",
       "         [ 0.11041719,  0.08959924,  0.05937142, ..., -0.044409  ,\n",
       "          -0.06203996, -0.1532538 ],\n",
       "         [ 0.08773427,  0.05811594,  0.02594864, ..., -0.07826544,\n",
       "          -0.11083362, -0.19827402],\n",
       "         ...,\n",
       "         [ 0.46532398,  0.5312795 ,  0.61323994, ...,  0.59645325,\n",
       "           0.58867764,  0.60123116],\n",
       "         [ 0.7514727 ,  0.777066  ,  0.7568235 , ...,  0.5731646 ,\n",
       "           0.54940474,  0.5644401 ],\n",
       "         [ 0.7612013 ,  0.791952  ,  0.71649027, ...,  0.6103969 ,\n",
       "           0.59294194,  0.5845068 ]],\n",
       "\n",
       "        [[ 0.11185893,  0.09900256,  0.07667108, ..., -0.03966907,\n",
       "          -0.07668927, -0.14249676],\n",
       "         [ 0.13101876,  0.11020081,  0.079973  , ..., -0.02087959,\n",
       "          -0.03851055, -0.12972438],\n",
       "         [ 0.11896381,  0.08934548,  0.05717818, ..., -0.05473603,\n",
       "          -0.08730421, -0.1747446 ],\n",
       "         ...,\n",
       "         [ 0.5193401 ,  0.58533883,  0.67571837, ...,  0.6953056 ,\n",
       "           0.67545205,  0.677497  ],\n",
       "         [ 0.8582374 ,  0.88451374,  0.8693738 , ...,  0.69932115,\n",
       "           0.6599073 ,  0.6561897 ],\n",
       "         [ 0.9200688 ,  0.9528599 ,  0.883026  , ...,  0.75119334,\n",
       "           0.7168569 ,  0.6853653 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"image\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e155ed-59aa-4c0c-89f1-85882e20c9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bacada-e3ef-49d4-b564-34e055beff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c478019b-dc56-4045-b720-afef4dca2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "valid_iterator = iter(valid_dataloader)\n",
    "valid_sample = next(valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19c9926f-66aa-4b63-8347-b0023da86dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 224, 224]), torch.Size([1]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features, val_labels = valid_sample[\"image\"],  valid_sample[\"label\"]\n",
    "\n",
    "val_features.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "137fe289-85f2-4411-ba3b-79fd58dbe0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_output = model(val_features)\n",
    "val_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6bac3c7-f2a4-4954-925f-f7d233716656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1322]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64c2e50a-a00b-47e5-8ac7-c1a5787d5b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1322], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_output.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca282a54-a4e3-4343-8112-cd1886263de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "246676f4-313c-40e1-9f5c-f65891b2be05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01d39811-20f8-4345-b1a8-45bf5e7484df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1418, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = loss_fn(val_output.view(-1), val_labels.type(torch.float))\n",
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e672a35b-0377-4547-a252-9a4cc3a7d7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce2ddb18-6681-4fdb-8d57-a34d2fcf8419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0599, -0.1396]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e0523-8b31-40fc-a6b5-e377897b5604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a787fb-1831-4b22-abde-6de0bb7f253f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8346d-59f3-4f16-b4f5-60cc8e17914a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84916dfc-e4fb-428b-8235-b67a039e7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b73978-73ad-4b8a-9ae6-6b5405d68d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692a7b4-797d-4deb-9f59-1e9b6934e522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a34695cf-690d-4b1c-8914-7e952b600040",
   "metadata": {},
   "source": [
    "## TODO: Tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd2c5d-b74a-41be-8b7f-1688a5595f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    return {\n",
    "        \"batch_size\": 8,\n",
    "        \"num_epochs\": 20,\n",
    "        \"lr\": 10**-4,\n",
    "        \"seq_len\": 350,\n",
    "        \"d_model\": 512,\n",
    "        \"datasource\": 'opus_books',\n",
    "        \"lang_src\": \"en\",\n",
    "        \"lang_tgt\": \"it\",\n",
    "        \"model_folder\": \"weights\",\n",
    "        \"model_basename\": \"tmodel_\",\n",
    "        \"preload\": \"latest\",\n",
    "        \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
    "        \"experiment_name\": \"runs/tmodel\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e692e31-6163-4d77-8101-b229a118acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3, 5]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "target.shape, input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af4a85-a654-4a56-835c-4697989b7f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48de5e-e1a4-4864-8e4f-48cdee3e9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODOS:\n",
    "- Multi gpu training\n",
    "- Load model and resume training\n",
    "- Freeze part of the model and train the rest\n",
    "- Initialize custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99598e5a-123b-4b0c-8cb2-be8b41ffba95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7785271b-8d89-4322-9da9-aa5d88d985b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c3c42-4c09-4333-8a97-1e00639276cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84e235-ca43-4fd9-b915-d170e6f6e2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ca67e-8773-42c0-99ef-72166cac5ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6653483-35e2-4e35-9a2a-0836222fb8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a4a877-bf94-4829-8469-0f9f879de943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffb0fa-2452-4cab-ad88-756b81947f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2b6d5-f4ad-4bc6-8779-ea803bc067d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e01c06-734c-46d7-815a-d9c3b63685f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567032e-09b3-4b58-a448-f152acd4edb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
