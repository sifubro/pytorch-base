{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe57561-cd10-4d5f-9003-eedf51309ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    '''\n",
    "    Full control on \n",
    "    '''\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = MyModel(input_size=10, hidden_size=20, output_size=5)\n",
    "\n",
    "# Access model parameters\n",
    "for param in model.parameters():\n",
    "    print(param.shape)  # Shape of each parameter tensor\n",
    "\n",
    "# Define optimizer and criterion\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Example training loop (omitting data loading and batching)\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, targets)  # Compute loss\n",
    "        loss.backward()  # Backward pass (compute gradients)\n",
    "        optimizer.step()  # Update model parameters\n",
    "    \n",
    "    # Optionally, log training metrics or evaluate the model\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b630f4-8f9a-4bb2-8823-24717b857748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeaaefb-37b6-4911-9168-6833e25d6be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aae8d19-e376-4921-bcbd-4fc46dc72266",
   "metadata": {},
   "source": [
    "## Define Neuron from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334ed02-01a2-4310-93e1-b5cd4a5c7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, input_dim, output_size, name=None):\n",
    "        super(Dense, self).__init__()\n",
    "        self.w = nn.Parameter(torch.randn(input_dim, output_size))  # Define weight as a parameter\n",
    "        self.b = nn.Parameter(torch.zeros(output_size))  # Define bias as a parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = torch.matmul(x, self.w) + self.b  # Compute linear transformation\n",
    "        return torch.relu(y)  # Apply ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daf2eb-9307-49c3-b766-8d8095927b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e42b1ef-e42f-4e50-84a7-824be1738bfe",
   "metadata": {},
   "source": [
    "### https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear\n",
    "### https://github.com/pytorch/pytorch/blob/main/torch/nn/init.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0bc8e1-6587-42f3-863c-2e1e5514ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
    "\n",
    "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
    "\n",
    "    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
    "\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to ``False``, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
    "          dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
    "        - Output: :math:`(*, H_{out})` where all but the last dimension\n",
    "          are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
    "\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
    "            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
    "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
    "                If :attr:`bias` is ``True``, the values are initialized from\n",
    "                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> m = nn.Linear(20, 30)\n",
    "        >>> input = torch.randn(128, 20)\n",
    "        >>> output = m(input)\n",
    "        >>> print(output.size())\n",
    "        torch.Size([128, 30])\n",
    "    \"\"\"\n",
    "\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
    "        # https://github.com/pytorch/pytorch/issues/57109\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd3397-abde-455a-aa14-9a8d1d8a4320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e130be-773e-4612-b2ba-4af69d42abeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171da087-fcb5-430d-84ef-012f7bfe372a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dec44667-0708-4c1b-a395-8a0f76a34d40",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "- Can I save the model using this format???\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192aac2-8142-42e6-a2f4-659afe2dd2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8476dd0-28ab-4302-b37c-5ee9e9c071d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859bcae-c368-4eb5-95f2-1251f717385f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f130e6-d500-408d-bdaa-030998f2757d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1631802-e583-40de-9e82-d6a881140e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba534b-ac8b-4983-83bd-c865422f45bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9d063-a92a-4e60-913b-770ee0407846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed029a7-7202-4dda-967b-332709eb0ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c2b29-832e-4ddf-a372-b681cd1ee79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e3405-be86-4e96-9eff-e73fe126742b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c735f-6b86-405c-a8fd-462590edd7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc70b81-d02d-409a-a330-67661644e992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeebe78-a02c-46bf-b33a-9f66f97d6dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
